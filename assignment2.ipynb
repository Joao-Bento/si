{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "JoÃ£o Bento \n",
    "\n",
    "95940\n",
    "\n",
    "Github link: https://github.com/Joao-Bento/si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Regression Problem with ANFIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "\n",
    "X = diabetes.data.values\n",
    "y = diabetes.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spliting\n",
    "test_size=0.2\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "Xtr= scaler.fit_transform(Xtr)\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters \n",
    "n_clusters = 2\n",
    "m=2\n",
    "\n",
    "# Concatenate target for clustering\n",
    "Xexp=np.concatenate([Xtr, ytr.reshape(-1, 1)], axis=1)\n",
    "#Xexp=Xtr\n",
    "\n",
    "# Transpose data for skfuzzy (expects features x samples)\n",
    "Xexp_T = Xexp.T \n",
    "\n",
    "# Fuzzy C-means clustering\n",
    "centers, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Xexp_T, n_clusters, m=m, error=0.005, maxiter=1000, init=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigma (spread) for each cluster\n",
    "sigmas = []\n",
    "for j in range(n_clusters):\n",
    "    # membership weights for cluster j, raised to m\n",
    "    u_j = u[j, :] ** m\n",
    "    # weighted variance for each feature\n",
    "    var_j = np.average((Xexp - centers[j])**2, axis=0, weights=u_j)\n",
    "    sigma_j = np.sqrt(var_j)\n",
    "    sigmas.append(sigma_j)\n",
    "sigmas=np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy partition coefficient (FPC): 0.8556218820367708\n"
     ]
    }
   ],
   "source": [
    "# Hard clustering from fuzzy membership\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "print(\"Fuzzy partition coefficient (FPC):\", fpc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian formula\n",
    "def gaussian(x, mu, sigma):\n",
    "    return np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
    "\n",
    "lin=np.linspace(-4, 4, 500)\n",
    "\n",
    "y_aux=[]\n",
    "for j in range(n_clusters):\n",
    "# Compute curves\n",
    "    y_aux.append(gaussian(lin, centers[j,0], sigmas[j,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gaussian Membership Function\n",
    "# ---------------------------\n",
    "class GaussianMF(nn.Module):\n",
    "    def __init__(self, centers, sigmas, agg_prob):\n",
    "        super().__init__()\n",
    "        self.centers = nn.Parameter(torch.tensor(centers, dtype=torch.float32))\n",
    "        self.sigmas = nn.Parameter(torch.tensor(sigmas, dtype=torch.float32))\n",
    "        self.agg_prob=agg_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand for broadcasting\n",
    "        # x: (batch, 1, n_dims), centers: (1, n_rules, n_dims), sigmas: (1, n_rules, n_dims)\n",
    "        diff = abs((x.unsqueeze(1) - self.centers.unsqueeze(0))/self.sigmas.unsqueeze(0)) #(batch, n_rules, n_dims)\n",
    "\n",
    "        # Aggregation\n",
    "        if self.agg_prob:\n",
    "            dist = torch.norm(diff, dim=-1)  # (batch, n_rules) # probablistic intersection\n",
    "        else:\n",
    "            dist = torch.max(diff, dim=-1).values  # (batch, n_rules) # min intersection (min instersection of normal funtion is the same as the max on dist)\n",
    "        \n",
    "        return torch.exp(-0.5 * dist ** 2)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# TSK Model\n",
    "# ---------------------------\n",
    "class TSK(nn.Module):\n",
    "    def __init__(self, n_inputs, n_rules, centers, sigmas,agg_prob=False):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_rules = n_rules\n",
    "\n",
    "        # Antecedents (Gaussian MFs)\n",
    "        \n",
    "        self.mfs=GaussianMF(centers, sigmas,agg_prob) \n",
    "\n",
    "        # Consequents (linear functions of inputs)\n",
    "        # Each rule has coeffs for each input + bias\n",
    "        self.consequents = nn.Parameter(\n",
    "            torch.randn(n_inputs + 1,n_rules)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, n_inputs)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Compute membership values for each input feature\n",
    "        # firing_strengths: (batch, n_rules)\n",
    "        firing_strengths = self.mfs(x)\n",
    "        \n",
    "        # Normalize memberships\n",
    "        # norm_fs: (batch, n_rules)\n",
    "        norm_fs = firing_strengths / (firing_strengths.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "        # Consequent output (linear model per rule)\n",
    "        x_aug = torch.cat([x, torch.ones(batch_size, 1)], dim=1)  # add bias\n",
    "\n",
    "        rule_outputs = torch.einsum(\"br,rk->bk\", x_aug, self.consequents)  # (batch, rules)\n",
    "        # Weighted sum\n",
    "        output = torch.sum(norm_fs * rule_outputs, dim=1, keepdim=True)\n",
    "\n",
    "        return output, norm_fs, rule_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANFIS Solver\n",
    "\n",
    "The only difference between this exercise and exercise 1 of assignment 1 is how the final model is trained. Using a simple least squares solver proved to inefficient in solving this regression problem, and thus a more complex training method was implemented: ANFIS. ANFIS stands for Adaptive Neuro-Fuzzy Inference System and can be defined as an hybrid system that combines fuzzy logic with neural networks, to create more robust models.\n",
    "\n",
    "It keeps the if-then rationale already described on the previous assignment. Note that on both procedures the modelling is donne with a TSK fuzzy system.\n",
    "\n",
    "On the other hand, the learning is donne with a more complex solver. ANFIS applies gradient descent training on antecedents of the TSK model (if rules), by minimizing a loss function with parameter optimization. However, consequents (then part) parameters are still identified by a least squares estimator. In sum, it combines forward and backward passes, as node outputs move forward with least squares, and error signals propagate backwards using gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Least Squares Solver for Consequents (TSK)\n",
    "# ---------------------------\n",
    "def train_ls(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        _, norm_fs, _ = model(X)\n",
    "\n",
    "        # Design matrix for LS: combine normalized firing strengths with input\n",
    "        X_aug = torch.cat([X, torch.ones(X.shape[0], 1)], dim=1)\n",
    "        \n",
    "        Phi = torch.einsum(\"br,bi->bri\", X_aug, norm_fs).reshape(X.shape[0], -1)\n",
    "        \n",
    "        # Solve LS: consequents = (Phi^T Phi)^-1 Phi^T y\n",
    "        \n",
    "        theta= torch.linalg.lstsq(Phi, y).solution\n",
    "    \n",
    "        \n",
    "        model.consequents.data = theta.reshape(model.consequents.shape)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gradient Descent Training \n",
    "# ---------------------------\n",
    "def train_gd(model, X, y, epochs=100, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _, _ = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Hybrid Training (Classic ANFIS)\n",
    "# ---------------------------\n",
    "def train_hybrid_anfis(model, X, y, max_iters=10, gd_epochs=20, lr=1e-3):\n",
    "    train_ls(model, X, y)\n",
    "    for _ in range(max_iters):\n",
    "        # Step A: GD on antecedents (freeze consequents)\n",
    "        model.consequents.requires_grad = False\n",
    "        train_gd(model, X, y, epochs=gd_epochs, lr=lr)\n",
    "\n",
    "        # Step B: LS on consequents (freeze antecedents)\n",
    "        model.consequents.requires_grad = True\n",
    "        model.mfs.requires_grad = False\n",
    "        train_ls(model, X, y)\n",
    "\n",
    "        # Re-enable antecedents\n",
    "        model.mfs.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "\n",
    "Xtr = torch.tensor(Xtr, dtype=torch.float32)\n",
    "ytr = torch.tensor(ytr, dtype=torch.float32)\n",
    "Xte = torch.tensor(Xte, dtype=torch.float32)\n",
    "yte = torch.tensor(yte, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2683.3916, grad_fn=<MseLossBackward0>)\n",
      "tensor(2682.0908, grad_fn=<MseLossBackward0>)\n",
      "tensor(2680.8711, grad_fn=<MseLossBackward0>)\n",
      "tensor(2679.6750, grad_fn=<MseLossBackward0>)\n",
      "tensor(2678.5166, grad_fn=<MseLossBackward0>)\n",
      "tensor(2677.4028, grad_fn=<MseLossBackward0>)\n",
      "tensor(2676.3206, grad_fn=<MseLossBackward0>)\n",
      "tensor(2675.2366, grad_fn=<MseLossBackward0>)\n",
      "tensor(2674.1299, grad_fn=<MseLossBackward0>)\n",
      "tensor(2673.0332, grad_fn=<MseLossBackward0>)\n",
      "tensor(2671.9397, grad_fn=<MseLossBackward0>)\n",
      "tensor(2670.8508, grad_fn=<MseLossBackward0>)\n",
      "tensor(2669.7744, grad_fn=<MseLossBackward0>)\n",
      "tensor(2668.6846, grad_fn=<MseLossBackward0>)\n",
      "tensor(2667.5984, grad_fn=<MseLossBackward0>)\n",
      "tensor(2666.5095, grad_fn=<MseLossBackward0>)\n",
      "tensor(2665.4287, grad_fn=<MseLossBackward0>)\n",
      "tensor(2664.3721, grad_fn=<MseLossBackward0>)\n",
      "tensor(2663.3250, grad_fn=<MseLossBackward0>)\n",
      "tensor(2662.2825, grad_fn=<MseLossBackward0>)\n",
      "tensor(2658.7925, grad_fn=<MseLossBackward0>)\n",
      "tensor(2657.5173, grad_fn=<MseLossBackward0>)\n",
      "tensor(2656.3000, grad_fn=<MseLossBackward0>)\n",
      "tensor(2655.0784, grad_fn=<MseLossBackward0>)\n",
      "tensor(2653.8914, grad_fn=<MseLossBackward0>)\n",
      "tensor(2652.7107, grad_fn=<MseLossBackward0>)\n",
      "tensor(2651.5452, grad_fn=<MseLossBackward0>)\n",
      "tensor(2650.3901, grad_fn=<MseLossBackward0>)\n",
      "tensor(2649.2498, grad_fn=<MseLossBackward0>)\n",
      "tensor(2648.1082, grad_fn=<MseLossBackward0>)\n",
      "tensor(2646.9785, grad_fn=<MseLossBackward0>)\n",
      "tensor(2645.8667, grad_fn=<MseLossBackward0>)\n",
      "tensor(2644.7563, grad_fn=<MseLossBackward0>)\n",
      "tensor(2643.6499, grad_fn=<MseLossBackward0>)\n",
      "tensor(2642.5564, grad_fn=<MseLossBackward0>)\n",
      "tensor(2641.4807, grad_fn=<MseLossBackward0>)\n",
      "tensor(2640.3962, grad_fn=<MseLossBackward0>)\n",
      "tensor(2639.3179, grad_fn=<MseLossBackward0>)\n",
      "tensor(2638.2490, grad_fn=<MseLossBackward0>)\n",
      "tensor(2637.1819, grad_fn=<MseLossBackward0>)\n",
      "tensor(2633.4802, grad_fn=<MseLossBackward0>)\n",
      "tensor(2632.0757, grad_fn=<MseLossBackward0>)\n",
      "tensor(2630.6853, grad_fn=<MseLossBackward0>)\n",
      "tensor(2629.3025, grad_fn=<MseLossBackward0>)\n",
      "tensor(2627.8406, grad_fn=<MseLossBackward0>)\n",
      "tensor(2626.3252, grad_fn=<MseLossBackward0>)\n",
      "tensor(2624.8186, grad_fn=<MseLossBackward0>)\n",
      "tensor(2623.3176, grad_fn=<MseLossBackward0>)\n",
      "tensor(2621.8208, grad_fn=<MseLossBackward0>)\n",
      "tensor(2620.3591, grad_fn=<MseLossBackward0>)\n",
      "tensor(2618.9119, grad_fn=<MseLossBackward0>)\n",
      "tensor(2617.4761, grad_fn=<MseLossBackward0>)\n",
      "tensor(2616.0574, grad_fn=<MseLossBackward0>)\n",
      "tensor(2614.6692, grad_fn=<MseLossBackward0>)\n",
      "tensor(2613.3152, grad_fn=<MseLossBackward0>)\n",
      "tensor(2611.9766, grad_fn=<MseLossBackward0>)\n",
      "tensor(2610.6609, grad_fn=<MseLossBackward0>)\n",
      "tensor(2609.3796, grad_fn=<MseLossBackward0>)\n",
      "tensor(2608.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(2606.8535, grad_fn=<MseLossBackward0>)\n",
      "tensor(2601.2371, grad_fn=<MseLossBackward0>)\n",
      "tensor(2599.5144, grad_fn=<MseLossBackward0>)\n",
      "tensor(2597.8572, grad_fn=<MseLossBackward0>)\n",
      "tensor(2596.2290, grad_fn=<MseLossBackward0>)\n",
      "tensor(2594.6292, grad_fn=<MseLossBackward0>)\n",
      "tensor(2593.0513, grad_fn=<MseLossBackward0>)\n",
      "tensor(2591.4988, grad_fn=<MseLossBackward0>)\n",
      "tensor(2589.9731, grad_fn=<MseLossBackward0>)\n",
      "tensor(2588.4856, grad_fn=<MseLossBackward0>)\n",
      "tensor(2587.0500, grad_fn=<MseLossBackward0>)\n",
      "tensor(2585.6375, grad_fn=<MseLossBackward0>)\n",
      "tensor(2584.2761, grad_fn=<MseLossBackward0>)\n",
      "tensor(2582.9290, grad_fn=<MseLossBackward0>)\n",
      "tensor(2581.6267, grad_fn=<MseLossBackward0>)\n",
      "tensor(2580.3606, grad_fn=<MseLossBackward0>)\n",
      "tensor(2579.1340, grad_fn=<MseLossBackward0>)\n",
      "tensor(2577.9482, grad_fn=<MseLossBackward0>)\n",
      "tensor(2576.8003, grad_fn=<MseLossBackward0>)\n",
      "tensor(2575.7119, grad_fn=<MseLossBackward0>)\n",
      "tensor(2574.6121, grad_fn=<MseLossBackward0>)\n",
      "tensor(2568.5784, grad_fn=<MseLossBackward0>)\n",
      "tensor(2567.0635, grad_fn=<MseLossBackward0>)\n",
      "tensor(2565.6101, grad_fn=<MseLossBackward0>)\n",
      "tensor(2564.2393, grad_fn=<MseLossBackward0>)\n",
      "tensor(2562.9016, grad_fn=<MseLossBackward0>)\n",
      "tensor(2561.6067, grad_fn=<MseLossBackward0>)\n",
      "tensor(2560.3604, grad_fn=<MseLossBackward0>)\n",
      "tensor(2559.1470, grad_fn=<MseLossBackward0>)\n",
      "tensor(2557.9397, grad_fn=<MseLossBackward0>)\n",
      "tensor(2556.7766, grad_fn=<MseLossBackward0>)\n",
      "tensor(2555.6550, grad_fn=<MseLossBackward0>)\n",
      "tensor(2554.5122, grad_fn=<MseLossBackward0>)\n",
      "tensor(2553.3936, grad_fn=<MseLossBackward0>)\n",
      "tensor(2552.3044, grad_fn=<MseLossBackward0>)\n",
      "tensor(2551.2419, grad_fn=<MseLossBackward0>)\n",
      "tensor(2550.2014, grad_fn=<MseLossBackward0>)\n",
      "tensor(2549.1641, grad_fn=<MseLossBackward0>)\n",
      "tensor(2548.1201, grad_fn=<MseLossBackward0>)\n",
      "tensor(2547.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(2546.0125, grad_fn=<MseLossBackward0>)\n",
      "tensor(2541.4326, grad_fn=<MseLossBackward0>)\n",
      "tensor(2539.9802, grad_fn=<MseLossBackward0>)\n",
      "tensor(2538.6028, grad_fn=<MseLossBackward0>)\n",
      "tensor(2537.2947, grad_fn=<MseLossBackward0>)\n",
      "tensor(2536.0439, grad_fn=<MseLossBackward0>)\n",
      "tensor(2534.8496, grad_fn=<MseLossBackward0>)\n",
      "tensor(2533.7200, grad_fn=<MseLossBackward0>)\n",
      "tensor(2532.5674, grad_fn=<MseLossBackward0>)\n",
      "tensor(2531.4141, grad_fn=<MseLossBackward0>)\n",
      "tensor(2530.2820, grad_fn=<MseLossBackward0>)\n",
      "tensor(2529.1609, grad_fn=<MseLossBackward0>)\n",
      "tensor(2528.0393, grad_fn=<MseLossBackward0>)\n",
      "tensor(2526.9036, grad_fn=<MseLossBackward0>)\n",
      "tensor(2525.7969, grad_fn=<MseLossBackward0>)\n",
      "tensor(2524.7109, grad_fn=<MseLossBackward0>)\n",
      "tensor(2523.7310, grad_fn=<MseLossBackward0>)\n",
      "tensor(2522.7595, grad_fn=<MseLossBackward0>)\n",
      "tensor(2521.7935, grad_fn=<MseLossBackward0>)\n",
      "tensor(2520.8301, grad_fn=<MseLossBackward0>)\n",
      "tensor(2519.8718, grad_fn=<MseLossBackward0>)\n",
      "tensor(2514.7676, grad_fn=<MseLossBackward0>)\n",
      "tensor(2512.6853, grad_fn=<MseLossBackward0>)\n",
      "tensor(2510.7837, grad_fn=<MseLossBackward0>)\n",
      "tensor(2509.0112, grad_fn=<MseLossBackward0>)\n",
      "tensor(2507.3618, grad_fn=<MseLossBackward0>)\n",
      "tensor(2505.7651, grad_fn=<MseLossBackward0>)\n",
      "tensor(2504.2144, grad_fn=<MseLossBackward0>)\n",
      "tensor(2502.7151, grad_fn=<MseLossBackward0>)\n",
      "tensor(2501.2690, grad_fn=<MseLossBackward0>)\n",
      "tensor(2499.8501, grad_fn=<MseLossBackward0>)\n",
      "tensor(2498.4475, grad_fn=<MseLossBackward0>)\n",
      "tensor(2497.0847, grad_fn=<MseLossBackward0>)\n",
      "tensor(2495.9709, grad_fn=<MseLossBackward0>)\n",
      "tensor(2495.0286, grad_fn=<MseLossBackward0>)\n",
      "tensor(2494.0881, grad_fn=<MseLossBackward0>)\n",
      "tensor(2493.1487, grad_fn=<MseLossBackward0>)\n",
      "tensor(2492.2195, grad_fn=<MseLossBackward0>)\n",
      "tensor(2491.3687, grad_fn=<MseLossBackward0>)\n",
      "tensor(2490.4871, grad_fn=<MseLossBackward0>)\n",
      "tensor(2489.5901, grad_fn=<MseLossBackward0>)\n",
      "tensor(2483.6963, grad_fn=<MseLossBackward0>)\n",
      "tensor(2482.1375, grad_fn=<MseLossBackward0>)\n",
      "tensor(2480.7073, grad_fn=<MseLossBackward0>)\n",
      "tensor(2479.3799, grad_fn=<MseLossBackward0>)\n",
      "tensor(2478.3042, grad_fn=<MseLossBackward0>)\n",
      "tensor(2477.3474, grad_fn=<MseLossBackward0>)\n",
      "tensor(2476.4141, grad_fn=<MseLossBackward0>)\n",
      "tensor(2475.4971, grad_fn=<MseLossBackward0>)\n",
      "tensor(2474.5950, grad_fn=<MseLossBackward0>)\n",
      "tensor(2473.7148, grad_fn=<MseLossBackward0>)\n",
      "tensor(2472.7837, grad_fn=<MseLossBackward0>)\n",
      "tensor(2471.8699, grad_fn=<MseLossBackward0>)\n",
      "tensor(2470.9307, grad_fn=<MseLossBackward0>)\n",
      "tensor(2470.0813, grad_fn=<MseLossBackward0>)\n",
      "tensor(2469.2493, grad_fn=<MseLossBackward0>)\n",
      "tensor(2468.3960, grad_fn=<MseLossBackward0>)\n",
      "tensor(2467.5425, grad_fn=<MseLossBackward0>)\n",
      "tensor(2466.7329, grad_fn=<MseLossBackward0>)\n",
      "tensor(2465.9707, grad_fn=<MseLossBackward0>)\n",
      "tensor(2465.1936, grad_fn=<MseLossBackward0>)\n",
      "tensor(2462.2014, grad_fn=<MseLossBackward0>)\n",
      "tensor(2461.0081, grad_fn=<MseLossBackward0>)\n",
      "tensor(2459.9087, grad_fn=<MseLossBackward0>)\n",
      "tensor(2459.0103, grad_fn=<MseLossBackward0>)\n",
      "tensor(2458.0564, grad_fn=<MseLossBackward0>)\n",
      "tensor(2457.2542, grad_fn=<MseLossBackward0>)\n",
      "tensor(2456.4331, grad_fn=<MseLossBackward0>)\n",
      "tensor(2455.5835, grad_fn=<MseLossBackward0>)\n",
      "tensor(2454.7361, grad_fn=<MseLossBackward0>)\n",
      "tensor(2453.9121, grad_fn=<MseLossBackward0>)\n",
      "tensor(2453.0461, grad_fn=<MseLossBackward0>)\n",
      "tensor(2452.1697, grad_fn=<MseLossBackward0>)\n",
      "tensor(2451.2615, grad_fn=<MseLossBackward0>)\n",
      "tensor(2450.3284, grad_fn=<MseLossBackward0>)\n",
      "tensor(2449.3706, grad_fn=<MseLossBackward0>)\n",
      "tensor(2448.4263, grad_fn=<MseLossBackward0>)\n",
      "tensor(2447.4897, grad_fn=<MseLossBackward0>)\n",
      "tensor(2446.5273, grad_fn=<MseLossBackward0>)\n",
      "tensor(2445.5737, grad_fn=<MseLossBackward0>)\n",
      "tensor(2444.7046, grad_fn=<MseLossBackward0>)\n",
      "tensor(2442.6980, grad_fn=<MseLossBackward0>)\n",
      "tensor(2441.6699, grad_fn=<MseLossBackward0>)\n",
      "tensor(2440.4565, grad_fn=<MseLossBackward0>)\n",
      "tensor(2439.2529, grad_fn=<MseLossBackward0>)\n",
      "tensor(2438.1990, grad_fn=<MseLossBackward0>)\n",
      "tensor(2437.1111, grad_fn=<MseLossBackward0>)\n",
      "tensor(2435.9880, grad_fn=<MseLossBackward0>)\n",
      "tensor(2434.8037, grad_fn=<MseLossBackward0>)\n",
      "tensor(2433.6350, grad_fn=<MseLossBackward0>)\n",
      "tensor(2432.4849, grad_fn=<MseLossBackward0>)\n",
      "tensor(2431.3633, grad_fn=<MseLossBackward0>)\n",
      "tensor(2430.2412, grad_fn=<MseLossBackward0>)\n",
      "tensor(2429.1367, grad_fn=<MseLossBackward0>)\n",
      "tensor(2428.3088, grad_fn=<MseLossBackward0>)\n",
      "tensor(2427.5386, grad_fn=<MseLossBackward0>)\n",
      "tensor(2426.7129, grad_fn=<MseLossBackward0>)\n",
      "tensor(2425.9243, grad_fn=<MseLossBackward0>)\n",
      "tensor(2425.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(2424.2480, grad_fn=<MseLossBackward0>)\n",
      "tensor(2423.4158, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Training with LS:\n",
    "train_hybrid_anfis(model, Xtr, ytr.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:2656.486328125\n",
      "RMSE:51.54111298880729\n"
     ]
    }
   ],
   "source": [
    "y_pred, _, _=model(Xte)\n",
    "#performance metric for regression\n",
    "print(f'MSE:{mean_squared_error(yte.detach().numpy(),y_pred.detach().numpy())}') #regression\n",
    "print(f'RMSE:{np.sqrt(mean_squared_error(yte.detach().numpy(),y_pred.detach().numpy()))}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y data range: 25.0 to 346.0\n"
     ]
    }
   ],
   "source": [
    "y_min = y.min()\n",
    "y_max = y.max()\n",
    "print(f\"y data range: {y_min} to {y_max}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although a more robust model was implemented, the performance did not change significantly. In fact, it got slightly worse (recall the MSE and RMSE for exercise 1 of assignment 1: 2545 and 50.45, respectively). Further comparison and improvements are discussed in the next exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Regression Problem with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "\n",
    "X = diabetes.data.values\n",
    "y = diabetes.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spliting\n",
    "test_size=0.2\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "Xtr= scaler.fit_transform(Xtr)\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "A neural network is a computational model inspired by the structure and functioning of the human brain. It is composed by nodes and layers. Nodes receive inputs, apply weights and biases and process the data using an activation function, passing the result to the next layer. Layers are collections of nodes, and can receive data (input layers), process data (hidden layers) or produce results (output layers). Furthermore, weights represent the strength of connection between nodes and biases allow the model to shift the activation function to better fit the data.\n",
    "\n",
    "In the NN architecture implemented below there are six layers (one for input, another for output and four hidden layers in between), each having 64 input and output features (except as global input and output of the network). All layers use ReLU (Rectified Linear Unit) functions as activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1, dropout_prob=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.out = nn.Linear(64, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Besides the number of hidden layers and type of activation functions, other hyperparameters can also be tuned to improve performance, such as the number of epochs, learning rate (lr), dropout ratio and batch size.\n",
    "\n",
    "The `number of epochs` refers to how many times the entire training dataset is passed through the model during training.\n",
    "\n",
    "The `learning rate` controls the step size at which the model updates its parameters (weights and biases) during training. \n",
    "\n",
    "`Dropout` is a regularization technique where a fraction of neurons is randomly \"dropped\" (set to zero) during training to prevent overfitting.\n",
    "\n",
    "The `batch size` determines the number of training samples processed before the model updates its parameters in one iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=100\n",
    "lr=0.0005\n",
    "dropout=0.1\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = torch.tensor(Xtr, dtype=torch.float32)\n",
    "ytr = torch.tensor(ytr, dtype=torch.float32)\n",
    "Xte = torch.tensor(Xte, dtype=torch.float32)\n",
    "yte = torch.tensor(yte, dtype=torch.float32)\n",
    "\n",
    "# Wrap Xtr and ytr into a dataset\n",
    "train_dataset = TensorDataset(Xtr, ytr)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Optimizer\n",
    "\n",
    "The `loss` is a measure of how well the model's predictions match the actual target values. It quantifies the error between the predicted output and the true output. The goal of training is to minimize this loss. The loss function is an evaluation metric specific to the task (MSE in this case, as we are dealing with a regression), and it is computed after each forward pass of the model.\n",
    "\n",
    "The `optimizer` is an algorithm that adjusts the model's parameters (weights and biases) to minimize the loss function. It updates the parameters based on the gradients computed during backpropagation. During this exercise, Adam algorithm was picked for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(input_size=Xtr.shape[1], dropout_prob=dropout).to(device)\n",
    "criterion = nn.MSELoss() #for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 29854.2754\n",
      "Epoch [2/100], Loss: 29405.4183\n",
      "Epoch [3/100], Loss: 29653.9163\n",
      "Epoch [4/100], Loss: 29537.0726\n",
      "Epoch [5/100], Loss: 29267.1247\n",
      "Epoch [6/100], Loss: 29280.7155\n",
      "Epoch [7/100], Loss: 29853.2559\n",
      "Epoch [8/100], Loss: 28738.7308\n",
      "Epoch [9/100], Loss: 29014.4219\n",
      "Epoch [10/100], Loss: 28795.2383\n",
      "Epoch [11/100], Loss: 28469.5046\n",
      "Epoch [12/100], Loss: 26561.0785\n",
      "Epoch [13/100], Loss: 26272.7441\n",
      "Epoch [14/100], Loss: 24648.4017\n",
      "Epoch [15/100], Loss: 21700.2900\n",
      "Epoch [16/100], Loss: 19612.9674\n",
      "Epoch [17/100], Loss: 15933.0267\n",
      "Epoch [18/100], Loss: 12783.7148\n",
      "Epoch [19/100], Loss: 9863.5323\n",
      "Epoch [20/100], Loss: 7552.8788\n",
      "Epoch [21/100], Loss: 7176.2053\n",
      "Epoch [22/100], Loss: 6119.1012\n",
      "Epoch [23/100], Loss: 5519.0241\n",
      "Epoch [24/100], Loss: 5269.5164\n",
      "Epoch [25/100], Loss: 4848.8540\n",
      "Epoch [26/100], Loss: 4848.6178\n",
      "Epoch [27/100], Loss: 5004.8229\n",
      "Epoch [28/100], Loss: 4498.3208\n",
      "Epoch [29/100], Loss: 4640.7030\n",
      "Epoch [30/100], Loss: 4949.0130\n",
      "Epoch [31/100], Loss: 4229.4655\n",
      "Epoch [32/100], Loss: 4103.3674\n",
      "Epoch [33/100], Loss: 4007.3798\n",
      "Epoch [34/100], Loss: 4338.3111\n",
      "Epoch [35/100], Loss: 3757.5972\n",
      "Epoch [36/100], Loss: 3921.0348\n",
      "Epoch [37/100], Loss: 3995.2573\n",
      "Epoch [38/100], Loss: 4054.1671\n",
      "Epoch [39/100], Loss: 3910.4493\n",
      "Epoch [40/100], Loss: 4049.4135\n",
      "Epoch [41/100], Loss: 3994.0029\n",
      "Epoch [42/100], Loss: 3840.0838\n",
      "Epoch [43/100], Loss: 3713.6421\n",
      "Epoch [44/100], Loss: 3999.0404\n",
      "Epoch [45/100], Loss: 3812.2281\n",
      "Epoch [46/100], Loss: 3696.9919\n",
      "Epoch [47/100], Loss: 3744.0612\n",
      "Epoch [48/100], Loss: 3759.2272\n",
      "Epoch [49/100], Loss: 3714.6593\n",
      "Epoch [50/100], Loss: 3836.4644\n",
      "Epoch [51/100], Loss: 3825.4545\n",
      "Epoch [52/100], Loss: 3703.6938\n",
      "Epoch [53/100], Loss: 3502.4794\n",
      "Epoch [54/100], Loss: 3670.0004\n",
      "Epoch [55/100], Loss: 3422.4111\n",
      "Epoch [56/100], Loss: 3403.7948\n",
      "Epoch [57/100], Loss: 3574.8393\n",
      "Epoch [58/100], Loss: 3605.0559\n",
      "Epoch [59/100], Loss: 3770.9301\n",
      "Epoch [60/100], Loss: 3449.6682\n",
      "Epoch [61/100], Loss: 3247.3246\n",
      "Epoch [62/100], Loss: 3556.6653\n",
      "Epoch [63/100], Loss: 3554.8926\n",
      "Epoch [64/100], Loss: 3478.9682\n",
      "Epoch [65/100], Loss: 3803.9688\n",
      "Epoch [66/100], Loss: 3357.5267\n",
      "Epoch [67/100], Loss: 3289.2096\n",
      "Epoch [68/100], Loss: 3448.9960\n",
      "Epoch [69/100], Loss: 3381.2710\n",
      "Epoch [70/100], Loss: 2975.3038\n",
      "Epoch [71/100], Loss: 3402.2066\n",
      "Epoch [72/100], Loss: 3245.2521\n",
      "Epoch [73/100], Loss: 3385.0117\n",
      "Epoch [74/100], Loss: 3425.0212\n",
      "Epoch [75/100], Loss: 3428.4788\n",
      "Epoch [76/100], Loss: 3482.8846\n",
      "Epoch [77/100], Loss: 3365.4736\n",
      "Epoch [78/100], Loss: 3308.3512\n",
      "Epoch [79/100], Loss: 3457.8031\n",
      "Epoch [80/100], Loss: 3193.3748\n",
      "Epoch [81/100], Loss: 3148.1761\n",
      "Epoch [82/100], Loss: 3076.5213\n",
      "Epoch [83/100], Loss: 2945.6698\n",
      "Epoch [84/100], Loss: 3257.9148\n",
      "Epoch [85/100], Loss: 3249.9101\n",
      "Epoch [86/100], Loss: 3049.1894\n",
      "Epoch [87/100], Loss: 3391.8554\n",
      "Epoch [88/100], Loss: 3457.8736\n",
      "Epoch [89/100], Loss: 3054.1117\n",
      "Epoch [90/100], Loss: 3045.8713\n",
      "Epoch [91/100], Loss: 3160.9581\n",
      "Epoch [92/100], Loss: 2948.4358\n",
      "Epoch [93/100], Loss: 3399.9195\n",
      "Epoch [94/100], Loss: 3183.3416\n",
      "Epoch [95/100], Loss: 3297.7530\n",
      "Epoch [96/100], Loss: 3125.0083\n",
      "Epoch [97/100], Loss: 3024.5865\n",
      "Epoch [98/100], Loss: 3268.9014\n",
      "Epoch [99/100], Loss: 3108.2592\n",
      "Epoch [100/100], Loss: 2999.8721\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        logits = model(batch_x)\n",
    "        loss = criterion(logits, batch_y.view(-1, 1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "plt.plot(range(1, num_epochs + 1), losses, label='Figure 1: Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:3422.1513671875\n",
      "RMSE:58.499156978434314\n"
     ]
    }
   ],
   "source": [
    "y_pred=model(Xte)\n",
    "print(f'MSE:{mean_squared_error(yte.detach().numpy(),y_pred.detach().numpy())}') #regression\n",
    "print(f'RMSE:{np.sqrt(mean_squared_error(yte.detach().numpy(),y_pred.detach().numpy()))}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the implemented model was unable to tackle the regression problem. All three models' performance metrics are displayed below:\n",
    "\n",
    " |-----|  simple TSK  |    ANFIS    |     NN      |\n",
    " |-----|--------------|-------------|-------------|\n",
    " |MSE  |          2545|         2656|        3422 |\n",
    " |RMSE |         50.45|       51.54 |        58.50|\n",
    "\n",
    " Even though neural networks are known to be more accurate than fuzzy systems, it was the NN model that performed worse. One could have argued whether there were enough epochs to train the model, but the loss evolution displayed on figure 1 quickly discards this claim, as the model shows only slight variations after epoch 30 and starts behaving somewhat stochastically. In order to try to improve performance, one could start by adding more hidden layers to the model (increasing complexity) and gradually decreasing the number of features of each layer seems reasonable. Further study is required to ascertain if the activation functions, optimization algorithm, learning rate, dropout ratio and batch size were required, but their tune is core to improve performance.\n",
    "\n",
    " Increasing model complexity from a simple TSK model to ANFIS also proved to be unsuccessful. However, further tuning of both its fuzzy and neuro inference components is likely to improve results, as described on previous assignment (fuzzy part) and on the above paragraph (neural network part),\n",
    "\n",
    " Due to its simplicity, explainability and overall performance, make the TSK fuzzy system the clear option for potential improvements to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Classification Problem with ANFIS\n",
    "\n",
    "For the sake of simplicity, a lesser study was conducted for this exercise, as the methodology and reasoning are very similar to exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
    "import skfuzzy as fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regression dataset\n",
    "diabetes = datasets.fetch_openml(\"diabetes\", version=1, as_frame=True)\n",
    "\n",
    "X = diabetes.data.values\n",
    "y = diabetes.target.values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spliting\n",
    "test_size=0.2\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "Xtr= scaler.fit_transform(Xtr)\n",
    "Xte= scaler.transform(Xte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters \n",
    "n_clusters = 2\n",
    "m=2\n",
    "\n",
    "# Concatenate target for clustering\n",
    "Xexp=np.concatenate([Xtr, ytr.reshape(-1, 1)], axis=1)\n",
    "#Xexp=Xtr\n",
    "\n",
    "# Transpose data for skfuzzy (expects features x samples)\n",
    "Xexp_T = Xexp.T \n",
    "\n",
    "# Fuzzy C-means clustering\n",
    "centers, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    Xexp_T, n_clusters, m=m, error=0.005, maxiter=1000, init=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sigma (spread) for each cluster\n",
    "sigmas = []\n",
    "for j in range(n_clusters):\n",
    "    # membership weights for cluster j, raised to m\n",
    "    u_j = u[j, :] ** m\n",
    "    # weighted variance for each feature\n",
    "    var_j = np.average((Xexp - centers[j])**2, axis=0, weights=u_j)\n",
    "    sigma_j = np.sqrt(var_j)\n",
    "    sigmas.append(sigma_j)\n",
    "sigmas=np.array(sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy partition coefficient (FPC): 0.500017338180851\n"
     ]
    }
   ],
   "source": [
    "# Hard clustering from fuzzy membership\n",
    "cluster_labels = np.argmax(u, axis=0)\n",
    "print(\"Fuzzy partition coefficient (FPC):\", fpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gaussian formula\n",
    "def gaussian(x, mu, sigma):\n",
    "    return np.exp(-0.5 * ((x - mu)/sigma)**2)\n",
    "\n",
    "lin=np.linspace(-4, 4, 500)\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "y_aux=[]\n",
    "for j in range(n_clusters):\n",
    "# Compute curves\n",
    "    y_aux.append(gaussian(lin, centers[j,0], sigmas[j,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gaussian Membership Function\n",
    "# ---------------------------\n",
    "class GaussianMF(nn.Module):\n",
    "    def __init__(self, centers, sigmas, agg_prob):\n",
    "        super().__init__()\n",
    "        self.centers = nn.Parameter(torch.tensor(centers, dtype=torch.float32))\n",
    "        self.sigmas = nn.Parameter(torch.tensor(sigmas, dtype=torch.float32))\n",
    "        self.agg_prob=agg_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expand for broadcasting\n",
    "        # x: (batch, 1, n_dims), centers: (1, n_rules, n_dims), sigmas: (1, n_rules, n_dims)\n",
    "        diff = abs((x.unsqueeze(1) - self.centers.unsqueeze(0))/self.sigmas.unsqueeze(0)) #(batch, n_rules, n_dims)\n",
    "\n",
    "        # Aggregation\n",
    "        if self.agg_prob:\n",
    "            dist = torch.norm(diff, dim=-1)  # (batch, n_rules) # probablistic intersection\n",
    "        else:\n",
    "            dist = torch.max(diff, dim=-1).values  # (batch, n_rules) # min intersection (min instersection of normal funtion is the same as the max on dist)\n",
    "        \n",
    "        return torch.exp(-0.5 * dist ** 2)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# TSK Model\n",
    "# ---------------------------\n",
    "class TSK(nn.Module):\n",
    "    def __init__(self, n_inputs, n_rules, centers, sigmas,agg_prob=False):\n",
    "        super().__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_rules = n_rules\n",
    "\n",
    "        # Antecedents (Gaussian MFs)\n",
    "        \n",
    "        self.mfs=GaussianMF(centers, sigmas,agg_prob) \n",
    "\n",
    "        # Consequents (linear functions of inputs)\n",
    "        # Each rule has coeffs for each input + bias\n",
    "        self.consequents = nn.Parameter(\n",
    "            torch.randn(n_inputs + 1,n_rules)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, n_inputs)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Compute membership values for each input feature\n",
    "        # firing_strengths: (batch, n_rules)\n",
    "        firing_strengths = self.mfs(x)\n",
    "        \n",
    "        # Normalize memberships\n",
    "        # norm_fs: (batch, n_rules)\n",
    "        norm_fs = firing_strengths / (firing_strengths.sum(dim=1, keepdim=True) + 1e-9)\n",
    "\n",
    "        # Consequent output (linear model per rule)\n",
    "        x_aug = torch.cat([x, torch.ones(batch_size, 1)], dim=1)  # add bias\n",
    "\n",
    "        rule_outputs = torch.einsum(\"br,rk->bk\", x_aug, self.consequents)  # (batch, rules)\n",
    "        # Weighted sum\n",
    "        output = torch.sum(norm_fs * rule_outputs, dim=1, keepdim=True)\n",
    "\n",
    "        return output, norm_fs, rule_outputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANFIS Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Least Squares Solver for Consequents (TSK)\n",
    "# ---------------------------\n",
    "def train_ls(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        _, norm_fs, _ = model(X)\n",
    "\n",
    "        # Design matrix for LS: combine normalized firing strengths with input\n",
    "        X_aug = torch.cat([X, torch.ones(X.shape[0], 1)], dim=1)\n",
    "        \n",
    "        Phi = torch.einsum(\"br,bi->bri\", X_aug, norm_fs).reshape(X.shape[0], -1)\n",
    "        \n",
    "        # Solve LS: consequents = (Phi^T Phi)^-1 Phi^T y\n",
    "        \n",
    "        theta= torch.linalg.lstsq(Phi, y).solution\n",
    "    \n",
    "        \n",
    "        model.consequents.data = theta.reshape(model.consequents.shape)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Gradient Descent Training \n",
    "# ---------------------------\n",
    "def train_gd(model, X, y, epochs=100, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _, _ = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Hybrid Training (Classic ANFIS)\n",
    "# ---------------------------\n",
    "def train_hybrid_anfis(model, X, y, max_iters=10, gd_epochs=20, lr=1e-3):\n",
    "    train_ls(model, X, y)\n",
    "    for _ in range(max_iters):\n",
    "        # Step A: GD on antecedents (freeze consequents)\n",
    "        model.consequents.requires_grad = False\n",
    "        train_gd(model, X, y, epochs=gd_epochs, lr=lr)\n",
    "\n",
    "        # Step B: LS on consequents (freeze antecedents)\n",
    "        model.consequents.requires_grad = True\n",
    "        model.mfs.requires_grad = False\n",
    "        train_ls(model, X, y)\n",
    "\n",
    "        # Re-enable antecedents\n",
    "        model.mfs.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = TSK(n_inputs=Xtr.shape[1], n_rules=n_clusters, centers=centers[:,:-1], sigmas=sigmas[:,:-1])\n",
    "\n",
    "Xtr = torch.tensor(Xtr, dtype=torch.float32)\n",
    "ytr = torch.tensor(ytr, dtype=torch.float32)\n",
    "Xte = torch.tensor(Xte, dtype=torch.float32)\n",
    "yte = torch.tensor(yte, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1528, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1526, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1510, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1507, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1506, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1502, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1497, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1499, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1498, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1497, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1494, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1493, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1491, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1489, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1488, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1470, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1478, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1466, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1467, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1464, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1460, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1461, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1462, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1460, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1458, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1457, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1447, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1450, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1446, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1440, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1443, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1442, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1440, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1437, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1437, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1438, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1428, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1425, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1422, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1422, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1422, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1421, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1433, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1423, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1419, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1419, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1413, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1434, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1410, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1417, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1429, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1416, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1407, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1405, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1401, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1427, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1414, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1399, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Training with LS:\n",
    "train_hybrid_anfis(model, Xtr, ytr.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:0.7662337662337663\n"
     ]
    }
   ],
   "source": [
    "y_pred, _, _=model(Xte)\n",
    "#performance metric for classification\n",
    "print(f'ACC:{accuracy_score(yte.detach().numpy(),y_pred.detach().numpy()>0.5)}') #classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, model performance is very similar with ANFIS and with a simple TSK (recall accuracy of 74.67%). Due to its simplicity the simple TSK fuzzy system seem preferable, however there is a deeper discussion on the next exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Classification Problem with Neural Networks\n",
    "\n",
    "For the sake of simplicity, a lesser study was conducted for this exercise, as the methodology and reasoning are very similar to exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Regression dataset\n",
    "diabetes = datasets.fetch_openml(\"diabetes\", version=1, as_frame=True)\n",
    "\n",
    "X = diabetes.data.values\n",
    "y = diabetes.target.values\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test spliting\n",
    "test_size=0.2\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler=StandardScaler()\n",
    "Xtr= scaler.fit_transform(Xtr)\n",
    "Xte= scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1, dropout_prob=0.5):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.out = nn.Linear(64, output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=100\n",
    "lr=0.0005\n",
    "dropout=0.1\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = torch.tensor(Xtr, dtype=torch.float32)\n",
    "ytr = torch.tensor(ytr, dtype=torch.float32)\n",
    "Xte = torch.tensor(Xte, dtype=torch.float32)\n",
    "yte = torch.tensor(yte, dtype=torch.float32)\n",
    "\n",
    "# Wrap Xtr and ytr into a dataset\n",
    "train_dataset = TensorDataset(Xtr, ytr)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, Loss, Optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(input_size=Xtr.shape[1], dropout_prob=dropout).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()  # for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6810\n",
      "Epoch [2/100], Loss: 0.6666\n",
      "Epoch [3/100], Loss: 0.6478\n",
      "Epoch [4/100], Loss: 0.6174\n",
      "Epoch [5/100], Loss: 0.5839\n",
      "Epoch [6/100], Loss: 0.5398\n",
      "Epoch [7/100], Loss: 0.5112\n",
      "Epoch [8/100], Loss: 0.4814\n",
      "Epoch [9/100], Loss: 0.4844\n",
      "Epoch [10/100], Loss: 0.4651\n",
      "Epoch [11/100], Loss: 0.4640\n",
      "Epoch [12/100], Loss: 0.4654\n",
      "Epoch [13/100], Loss: 0.4391\n",
      "Epoch [14/100], Loss: 0.4445\n",
      "Epoch [15/100], Loss: 0.4563\n",
      "Epoch [16/100], Loss: 0.4493\n",
      "Epoch [17/100], Loss: 0.4507\n",
      "Epoch [18/100], Loss: 0.4516\n",
      "Epoch [19/100], Loss: 0.4537\n",
      "Epoch [20/100], Loss: 0.4461\n",
      "Epoch [21/100], Loss: 0.4316\n",
      "Epoch [22/100], Loss: 0.4517\n",
      "Epoch [23/100], Loss: 0.4321\n",
      "Epoch [24/100], Loss: 0.4370\n",
      "Epoch [25/100], Loss: 0.4295\n",
      "Epoch [26/100], Loss: 0.4241\n",
      "Epoch [27/100], Loss: 0.4428\n",
      "Epoch [28/100], Loss: 0.4250\n",
      "Epoch [29/100], Loss: 0.4211\n",
      "Epoch [30/100], Loss: 0.4235\n",
      "Epoch [31/100], Loss: 0.4290\n",
      "Epoch [32/100], Loss: 0.4198\n",
      "Epoch [33/100], Loss: 0.4249\n",
      "Epoch [34/100], Loss: 0.4217\n",
      "Epoch [35/100], Loss: 0.4267\n",
      "Epoch [36/100], Loss: 0.4062\n",
      "Epoch [37/100], Loss: 0.4109\n",
      "Epoch [38/100], Loss: 0.4217\n",
      "Epoch [39/100], Loss: 0.4118\n",
      "Epoch [40/100], Loss: 0.3983\n",
      "Epoch [41/100], Loss: 0.4165\n",
      "Epoch [42/100], Loss: 0.3958\n",
      "Epoch [43/100], Loss: 0.4037\n",
      "Epoch [44/100], Loss: 0.4091\n",
      "Epoch [45/100], Loss: 0.3981\n",
      "Epoch [46/100], Loss: 0.3962\n",
      "Epoch [47/100], Loss: 0.4073\n",
      "Epoch [48/100], Loss: 0.4061\n",
      "Epoch [49/100], Loss: 0.3824\n",
      "Epoch [50/100], Loss: 0.3823\n",
      "Epoch [51/100], Loss: 0.3886\n",
      "Epoch [52/100], Loss: 0.3936\n",
      "Epoch [53/100], Loss: 0.4008\n",
      "Epoch [54/100], Loss: 0.3716\n",
      "Epoch [55/100], Loss: 0.3935\n",
      "Epoch [56/100], Loss: 0.3911\n",
      "Epoch [57/100], Loss: 0.3753\n",
      "Epoch [58/100], Loss: 0.3804\n",
      "Epoch [59/100], Loss: 0.3663\n",
      "Epoch [60/100], Loss: 0.3697\n",
      "Epoch [61/100], Loss: 0.3697\n",
      "Epoch [62/100], Loss: 0.3778\n",
      "Epoch [63/100], Loss: 0.3962\n",
      "Epoch [64/100], Loss: 0.3609\n",
      "Epoch [65/100], Loss: 0.3850\n",
      "Epoch [66/100], Loss: 0.3814\n",
      "Epoch [67/100], Loss: 0.3645\n",
      "Epoch [68/100], Loss: 0.3604\n",
      "Epoch [69/100], Loss: 0.3706\n",
      "Epoch [70/100], Loss: 0.3504\n",
      "Epoch [71/100], Loss: 0.3657\n",
      "Epoch [72/100], Loss: 0.3684\n",
      "Epoch [73/100], Loss: 0.3562\n",
      "Epoch [74/100], Loss: 0.3585\n",
      "Epoch [75/100], Loss: 0.3556\n",
      "Epoch [76/100], Loss: 0.3512\n",
      "Epoch [77/100], Loss: 0.3396\n",
      "Epoch [78/100], Loss: 0.3412\n",
      "Epoch [79/100], Loss: 0.3381\n",
      "Epoch [80/100], Loss: 0.3533\n",
      "Epoch [81/100], Loss: 0.3708\n",
      "Epoch [82/100], Loss: 0.3481\n",
      "Epoch [83/100], Loss: 0.3335\n",
      "Epoch [84/100], Loss: 0.3296\n",
      "Epoch [85/100], Loss: 0.3488\n",
      "Epoch [86/100], Loss: 0.3484\n",
      "Epoch [87/100], Loss: 0.3439\n",
      "Epoch [88/100], Loss: 0.3226\n",
      "Epoch [89/100], Loss: 0.3470\n",
      "Epoch [90/100], Loss: 0.3214\n",
      "Epoch [91/100], Loss: 0.3279\n",
      "Epoch [92/100], Loss: 0.3286\n",
      "Epoch [93/100], Loss: 0.3354\n",
      "Epoch [94/100], Loss: 0.3382\n",
      "Epoch [95/100], Loss: 0.3219\n",
      "Epoch [96/100], Loss: 0.3297\n",
      "Epoch [97/100], Loss: 0.3237\n",
      "Epoch [98/100], Loss: 0.3101\n",
      "Epoch [99/100], Loss: 0.3337\n",
      "Epoch [100/100], Loss: 0.3229\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_x, batch_y in train_dataloader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "\n",
    "        logits = model(batch_x)\n",
    "        loss = criterion(logits, batch_y.view(-1, 1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_dataloader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.plot(range(1, num_epochs + 1), losses, label='Figure 2: Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "y_pred=model(Xte)\n",
    "print(f'ACC:{accuracy_score(yte.detach().numpy(),y_pred.detach().numpy()>0.5)}') #classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " |-----|  simple TSK  |    ANFIS    |     NN      |\n",
    " |-----|--------------|-------------|-------------|\n",
    " |ACC  |        74.67%|       76.62%|       74.02%|\n",
    "\n",
    " Once again, all models perform very similarly and still far from ideal. Improvements procedures are very similar to what was previously described on exercise 2. However, I would point the NN as the one with most potential for improvements, as neural networks are known to be generally more accurate than fuzzy systems and their performance being so close. Furthermore, figure 2 shows that train loss is decreasing throughout epochs and that increasing the number of epochs is likely to make the model reach a better accuracy. Yet, if one is also interested in understanding the decision making behind the model, the ANFIS model would be the adequate choice.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
